{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Setup**"
      ],
      "metadata": {
        "id": "01s2R9q7Cyc2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please note that if you accessed this notebook through the Colab button on GitHub then your data will be stored in an ephemeral session storage drive. Any important analysis should be saved before closing the notebook. In this case it might be more convenient to upload data directly into the session storage (Folder icon aka 'Files' > File upload icon aka 'Upload to session storage')\n",
        "\n",
        "Sample input files are available at - https://github.com/Rayyan-Tariq-Khan/ProteoViz/tree/main/Input\n",
        "\n",
        "You may also **optionally** download them directly into the ephemeral drive using the cell below-"
      ],
      "metadata": {
        "id": "5iKna6Vpad4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "\n",
        "# List of files with their URLs and local file names\n",
        "files = [\n",
        "    {\n",
        "        \"url\": \"https://raw.githubusercontent.com/Rayyan-Tariq-Khan/ProteoViz/main/Input/PXD037757.txt\",\n",
        "        \"file_name\": \"PXD037757.txt\"\n",
        "    },\n",
        "    {\n",
        "        \"url\": \"https://raw.githubusercontent.com/Rayyan-Tariq-Khan/ProteoViz/main/Input/Complexes.xlsx\",\n",
        "        \"file_name\": \"Complexes.xlsx\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Download and save each file\n",
        "for file in files:\n",
        "    try:\n",
        "        urllib.request.urlretrieve(file[\"url\"], file[\"file_name\"])\n",
        "        print(f\"File '{file['file_name']}' downloaded and saved successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while downloading '{file['file_name']}': {e}\")\n"
      ],
      "metadata": {
        "id": "GcKNUHZnlZ--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Filtering**\n"
      ],
      "metadata": {
        "id": "VjParhRXIrPp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell requires a full MaxQuant like ('Protein groups') .tsv output sheet with a .txt extension. It lets you filter out positive hits in these 3 columns - 'Reverse', 'Only identified by site', and 'Potential contaminant'.\n",
        "\n",
        "Sample input files can be downloaded from the code cell above and they are also available at - https://github.com/Rayyan-Tariq-Khan/ProteoViz/tree/main/Input\n",
        "\n",
        "**Important Note** - You may upload your own Input file, but kindly change the name of the 'input_file' variable to reflect this."
      ],
      "metadata": {
        "id": "9UikHwGGO8ke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Define the input and output file paths\n",
        "input_file = '/content/PXD037757.txt'  # Input is now a TSV file with .txt extension\n",
        "output_file = '/content/proteinGroups_filtered.txt'  # Output is a TSV file with .txt extension\n",
        "\n",
        "# Check if the input file exists\n",
        "if not os.path.exists(input_file):\n",
        "    print(f\"Input file '{input_file}' does not exist.\")\n",
        "else:\n",
        "    # Load the TSV file into a pandas DataFrame\n",
        "    df = pd.read_csv(input_file, sep='\\t')\n",
        "    print(\"TSV file loaded successfully.\")\n",
        "\n",
        "    # Print the initial number of rows\n",
        "    initial_row_count = len(df)\n",
        "    print(f\"Initial number of rows: {initial_row_count}\")\n",
        "\n",
        "    # Check if the required columns exist\n",
        "    required_columns = ['Only identified by site', 'Reverse', 'Potential contaminant']\n",
        "    missing_columns = [col for col in required_columns if col not in df.columns]\n",
        "\n",
        "    if not missing_columns:\n",
        "        print(\"All required columns are present.\")\n",
        "\n",
        "        # Filter rows where 'Reverse' has a '+'\n",
        "        df_filtered = df[df['Reverse'] != '+']\n",
        "        print(f\"Rows after filtering 'Reverse': {len(df_filtered)}\")\n",
        "\n",
        "        # Further remove rows where 'Only identified by site' has a '+'\n",
        "        df_filtered = df_filtered[df_filtered['Only identified by site'] != '+']\n",
        "        print(f\"Rows after filtering 'Only identified by site': {len(df_filtered)}\")\n",
        "\n",
        "        # Further remove rows where 'Potential contaminant' has a '+'\n",
        "        df_filtered = df_filtered[df_filtered['Potential contaminant'] != '+']\n",
        "        print(f\"Rows after filtering 'Potential contaminant': {len(df_filtered)}\")\n",
        "\n",
        "        # Save the filtered DataFrame to a new TSV file with .txt extension\n",
        "        if not df_filtered.empty:\n",
        "            df_filtered.to_csv(output_file, sep='\\t', index=False)\n",
        "            print(f\"Filtered file has been saved as {output_file}\")\n",
        "        else:\n",
        "            print(\"No data left after filtering. No file will be saved.\")\n",
        "    else:\n",
        "        print(f\"Missing columns: {', '.join(missing_columns)} not found in the file.\")\n"
      ],
      "metadata": {
        "id": "bOOst7kh5Yhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell lets you keep 1 or 2 identifier columns from the original sheet. It also lets you select which abundance values to keep in the filtered sheet."
      ],
      "metadata": {
        "id": "Sq-zvovcQP5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "\n",
        "# Define the input and output file paths\n",
        "input_file = '/content/proteinGroups_filtered.txt'  # Input is now a TSV file with .txt extension\n",
        "output_file = '/content/proteinGroups_filtered.txt'  # Output will be a TSV file with .txt extension\n",
        "\n",
        "# Check if the input file exists\n",
        "if not os.path.exists(input_file):\n",
        "    print(f\"Input file '{input_file}' does not exist.\")\n",
        "    exit()\n",
        "\n",
        "# Load the TSV file into a pandas DataFrame\n",
        "df = pd.read_csv(input_file, sep='\\t')\n",
        "print(\"TSV file loaded successfully.\")\n",
        "\n",
        "# Step 1: Ask the user for the number of identifier columns\n",
        "num_identifiers = input(\"How many identifier columns do you have in your sheet? (Enter 1 or 2): \")\n",
        "\n",
        "# Validate user input\n",
        "if num_identifiers not in ['1', '2']:\n",
        "    print(\"Invalid input. Please enter 1 or 2.\")\n",
        "    exit()\n",
        "\n",
        "# Get the identifier columns from user input\n",
        "identifier_columns = []\n",
        "if num_identifiers == '1':\n",
        "    identifier_column_name = input(\"Enter the header of the identifier column: \")\n",
        "    if identifier_column_name not in df.columns:\n",
        "        print(f\"Column '{identifier_column_name}' not found in the sheet.\")\n",
        "        exit()\n",
        "    identifier_columns = [identifier_column_name]\n",
        "    id_prefix = '_1id'\n",
        "else:\n",
        "    identifier_column_name1 = input(\"Enter the header of the first identifier column: \")\n",
        "    identifier_column_name2 = input(\"Enter the header of the second identifier column: \")\n",
        "    if identifier_column_name1 not in df.columns or identifier_column_name2 not in df.columns:\n",
        "        print(\"One or both of the specified identifier columns are not found in the sheet.\")\n",
        "        exit()\n",
        "    identifier_columns = [identifier_column_name1, identifier_column_name2]\n",
        "    id_prefix = '_2id'\n",
        "\n",
        "# Replace empty cells in identifier columns with 'Missing ID'\n",
        "df[identifier_columns] = df[identifier_columns].fillna('Missing ID')\n",
        "\n",
        "# Step 2: Ask the user to choose the column series\n",
        "print(\"Choose the column series you want to include:\")\n",
        "print(\"1. Intensity wtXX columns\")\n",
        "print(\"2. iBAQ wtXX columns\")\n",
        "print(\"3. Self-selected list of columns\")\n",
        "column_choice = input(\"Enter your choice (1, 2, or 3): \")\n",
        "\n",
        "# Validate user input\n",
        "if column_choice not in ['1', '2', '3']:\n",
        "    print(\"Invalid input. Please enter 1, 2, or 3.\")\n",
        "    exit()\n",
        "\n",
        "# Determine the series of columns to save based on user choice\n",
        "if column_choice == '1':\n",
        "    # Find the Intensity wtXX columns\n",
        "    intensity_columns = [col for col in df.columns if re.match(r'^Intensity wt\\d+$', col)]\n",
        "    if intensity_columns:\n",
        "        selected_columns = identifier_columns + intensity_columns\n",
        "        column_prefix = '_Intensity'\n",
        "    else:\n",
        "        print(\"No 'Intensity wtXX' columns found.\")\n",
        "        exit()\n",
        "elif column_choice == '2':\n",
        "    # Find the iBAQ wtXX columns\n",
        "    ibaq_columns = [col for col in df.columns if re.match(r'^iBAQ wt\\d+$', col)]\n",
        "    if ibaq_columns:\n",
        "        selected_columns = identifier_columns + ibaq_columns\n",
        "        column_prefix = '_IBAQ'\n",
        "    else:\n",
        "        print(\"No 'iBAQ wtXX' columns found.\")\n",
        "        exit()\n",
        "elif column_choice == '3':\n",
        "    # Ask user for self-selected columns\n",
        "    first_col = input(\"Enter the header of the first column in the range: \")\n",
        "    last_col = input(\"Enter the header of the last column in the range: \")\n",
        "\n",
        "    if first_col in df.columns and last_col in df.columns:\n",
        "        start_index = df.columns.get_loc(first_col)\n",
        "        end_index = df.columns.get_loc(last_col)\n",
        "        if start_index <= end_index:\n",
        "            selected_columns = identifier_columns + df.columns[start_index:end_index + 1].tolist()\n",
        "            column_prefix = '_selection'\n",
        "        else:\n",
        "            print(\"The first column must appear before the last column in the sheet.\")\n",
        "            exit()\n",
        "    else:\n",
        "        print(\"One or both of the specified columns are not found in the sheet.\")\n",
        "        exit()\n",
        "\n",
        "# Create a new DataFrame with the selected columns\n",
        "filtered_df = df[selected_columns]\n",
        "\n",
        "# Rename the headers of non-identifier columns to a sequence of numbers starting from 1\n",
        "non_identifier_columns = filtered_df.columns[len(identifier_columns):]  # Select non-identifier columns\n",
        "new_column_names = identifier_columns + list(range(1, len(non_identifier_columns) + 1))\n",
        "filtered_df.columns = new_column_names\n",
        "\n",
        "# Construct the output file name\n",
        "output_file = f'/content/proteinGroups_filtered{id_prefix}{column_prefix}.txt'\n",
        "\n",
        "# Save the filtered DataFrame to a new TSV file with .txt extension\n",
        "filtered_df.to_csv(output_file, sep='\\t', index=False)\n",
        "\n",
        "print(f\"The new file has been saved as {output_file}\")\n"
      ],
      "metadata": {
        "id": "58dMLGz79al4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Log transform** (optional)"
      ],
      "metadata": {
        "id": "LnjVFsV6VY4q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell lets you apply multiple kinds of log transformations to the filtered abundances sheet"
      ],
      "metadata": {
        "id": "ETm1FDvoQngt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import os\n",
        "import math\n",
        "\n",
        "# Define the input file path (TSV format)\n",
        "input_file = '/content/proteinGroups_filtered_2id_selection.txt'\n",
        "\n",
        "# Check if the input file exists\n",
        "if not os.path.exists(input_file):\n",
        "    print(f\"Input file '{input_file}' does not exist.\")\n",
        "    exit()\n",
        "\n",
        "# Load the TSV file into a pandas DataFrame\n",
        "df = pd.read_csv(input_file, sep='\\t')\n",
        "print(\"TSV file loaded successfully.\")\n",
        "\n",
        "# Step 1: Ask the user for the number of identifier columns\n",
        "num_identifiers = input(\"How many identifier columns are there? (Enter 1 or 2): \")\n",
        "\n",
        "# Validate user input\n",
        "if num_identifiers not in ['1', '2']:\n",
        "    print(\"Invalid input. Please enter 1 or 2.\")\n",
        "    exit()\n",
        "\n",
        "# Step 2: Ask the user to choose the log transformation type\n",
        "print(\"Choose the type of log transformation:\")\n",
        "print(\"1. Natural (base e)\")\n",
        "print(\"2. Binary (base 2)\")\n",
        "print(\"3. Common (base 10)\")\n",
        "print(\"4. Custom base\")\n",
        "log_choice = input(\"Enter your choice (1, 2, 3, or 4): \")\n",
        "\n",
        "# Validate user input\n",
        "if log_choice not in ['1', '2', '3', '4']:\n",
        "    print(\"Invalid input. Please enter 1, 2, 3, or 4.\")\n",
        "    exit()\n",
        "\n",
        "# Define the log transformation function based on user choice\n",
        "def log_transform(x, base):\n",
        "    return np.log(x) / np.log(base)\n",
        "\n",
        "# Step 3: Ask the user how to handle 0 or NaN values\n",
        "print(\"How do you want to treat 0 or NaN values?\")\n",
        "print(\"1. Change to 1\")\n",
        "print(\"2. Conventional method/Treat as 1\")\n",
        "print(\"3. Type in a constant\")\n",
        "print(\"4. Leave as is\")\n",
        "zero_choice = input(\"Enter your choice (1, 2, 3, or 4): \")\n",
        "\n",
        "# Validate user input\n",
        "if zero_choice not in ['1', '2', '3', '4']:\n",
        "    print(\"Invalid input. Please enter 1, 2, 3, or 4.\")\n",
        "    exit()\n",
        "\n",
        "# Get the log base\n",
        "if log_choice == '1':\n",
        "    base = math.e\n",
        "    log_suffix = '_Natural'\n",
        "elif log_choice == '2':\n",
        "    base = 2\n",
        "    log_suffix = '_Binary'\n",
        "elif log_choice == '3':\n",
        "    base = 10\n",
        "    log_suffix = '_Common'\n",
        "else:\n",
        "    base = float(input(\"Enter the custom base for the log transformation: \"))\n",
        "    log_suffix = f'_Base{int(base)}'\n",
        "\n",
        "# Handle zero and NaN values\n",
        "if zero_choice == '1':\n",
        "    fill_value = 1\n",
        "    fill_suffix = '_constant1'\n",
        "elif zero_choice == '2':\n",
        "    fill_value = 1\n",
        "    fill_suffix = '_constant1'\n",
        "elif zero_choice == '3':\n",
        "    fill_value = float(input(\"Enter the constant value to replace 0 and NaN: \"))\n",
        "    fill_suffix = f'_constant{int(fill_value)}'\n",
        "else:\n",
        "    fill_value = None\n",
        "    fill_suffix = ''\n",
        "\n",
        "# Apply the chosen fill method\n",
        "if fill_value is not None:\n",
        "    df = df.fillna(fill_value)\n",
        "    df.iloc[:, int(num_identifiers):] = df.iloc[:, int(num_identifiers):].replace(0, fill_value)\n",
        "\n",
        "# Apply the log transformation to the appropriate columns\n",
        "data_columns = df.columns[int(num_identifiers):]\n",
        "df[data_columns] = df[data_columns].apply(lambda x: log_transform(x, base))\n",
        "\n",
        "# Construct the output file name (TSV format with .txt extension)\n",
        "output_file = f'/content/proteinGroups_filtered_2id_selection{log_suffix}{fill_suffix}.txt'\n",
        "\n",
        "# Save the transformed DataFrame to a new TSV file\n",
        "df.to_csv(output_file, sep='\\t', index=False)\n",
        "\n",
        "print(f\"The transformed file has been saved as {output_file}\")\n"
      ],
      "metadata": {
        "id": "HIlXOso3_3D7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Profile Plots**"
      ],
      "metadata": {
        "id": "jNmJlRJtUIub"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell lets you plot profiles of various proteins from the filtered sheet. It also lets you pick alternate legend labels."
      ],
      "metadata": {
        "id": "PhGs5NQ5RB5n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "\n",
        "# Load the test_pfd.txt file\n",
        "test_pfd_path = '/content/proteinGroups_filtered_2id_selection.txt'\n",
        "test_pfd_df = pd.read_csv(test_pfd_path, sep='\\t')\n",
        "\n",
        "# Ask the user how many identifier columns are present\n",
        "num_identifier_columns = int(input(\"How many identifier columns do you have (1 or 2)? \"))\n",
        "\n",
        "if num_identifier_columns == 2:\n",
        "    # Display options for identifier column (for input)\n",
        "    print(\"Select the identifier column you want to use to input protein names:\")\n",
        "    print(f\"1: {test_pfd_df.columns[0]} (first column identifier)\")\n",
        "    print(f\"2: {test_pfd_df.columns[1]} (second column identifier)\")\n",
        "    identifier_choice_input = input(\"Enter 1 or 2: \")\n",
        "\n",
        "    # Display options for legend labels\n",
        "    print(\"Select the identifier column(s) you want to use for legend labels:\")\n",
        "    print(f\"1: {test_pfd_df.columns[0]} (first column identifier)\")\n",
        "    print(f\"2: {test_pfd_df.columns[1]} (second column identifier)\")\n",
        "    print(\"3: Combine both columns as identifiers\")\n",
        "    identifier_choice_legend = input(\"Enter 1, 2, or 3: \")\n",
        "else:\n",
        "    identifier_choice_input = '1'\n",
        "    identifier_choice_legend = '1'\n",
        "\n",
        "# Prompt the user for the list of protein names\n",
        "protein_names = input(\"Enter the protein names separated by commas: \").split(',')\n",
        "\n",
        "# Clean up the protein names list\n",
        "protein_names = [protein.strip() for protein in protein_names if protein]  # Remove any empty strings\n",
        "\n",
        "# Choose the appropriate column for input identifiers\n",
        "if identifier_choice_input == '1':\n",
        "    input_column = test_pfd_df.columns[0]\n",
        "elif identifier_choice_input == '2':\n",
        "    input_column = test_pfd_df.columns[1]\n",
        "\n",
        "# Find the matching rows in test_pfd.txt based on the input protein names\n",
        "# Modified to check if IDs may be inside grouping (e.g., separated by semicolons)\n",
        "matching_rows = test_pfd_df[test_pfd_df[input_column].apply(\n",
        "    lambda cell: isinstance(cell, str) and any(protein in cell.split(';') for protein in protein_names)\n",
        ")]\n",
        "\n",
        "if matching_rows.empty:\n",
        "    print(\"No matching proteins found in the selected identifier column.\")\n",
        "else:\n",
        "    # Prepare the data for plotting\n",
        "    x_values = test_pfd_df.columns[2:]  # X-axis values from the headers (excluding the first two columns)\n",
        "\n",
        "    # Create the plot\n",
        "    fig = go.Figure()\n",
        "\n",
        "    for _, row in matching_rows.iterrows():\n",
        "        y_values = row[2:].values  # Y-values for the heatmap\n",
        "        y_values = pd.to_numeric(y_values, errors='coerce')  # Ensure values are numeric\n",
        "        y_values = np.nan_to_num(y_values)  # Replace NaNs with 0\n",
        "\n",
        "        # Determine the line label based on the user's choice\n",
        "        if identifier_choice_legend == '1':\n",
        "            line_label = row[test_pfd_df.columns[0]]  # First column identifier\n",
        "        elif identifier_choice_legend == '2':\n",
        "            line_label = row[test_pfd_df.columns[1]]  # Second column identifier\n",
        "        elif identifier_choice_legend == '3':\n",
        "            line_label = f\"{row[test_pfd_df.columns[0]]} / {row[test_pfd_df.columns[1]]}\"  # Combined identifiers\n",
        "\n",
        "        # Add the line to the plot\n",
        "        fig.add_trace(go.Scatter(x=x_values, y=y_values, mode='lines', name=line_label))\n",
        "\n",
        "    # Determine if the file is log-transformed based on its name\n",
        "    filename = os.path.basename(test_pfd_path)\n",
        "    log_transformed_suffix = \"\"\n",
        "    if \"_Natural\" in filename:\n",
        "        log_transformed_suffix = \"Natural Log Transformed\"\n",
        "    elif \"_Binary\" in filename:\n",
        "        log_transformed_suffix = \"Binary Log Transformed\"\n",
        "    elif \"_Common\" in filename:\n",
        "        log_transformed_suffix = \"Common Log Transformed\"\n",
        "    elif \"_Base\" in filename:\n",
        "        # Extract the base number using a regular expression\n",
        "        base_match = re.search(r\"_Base(\\d+)\", filename)\n",
        "        if base_match:\n",
        "            base_number = base_match.group(1)  # Get the number after \"_Base\"\n",
        "            log_transformed_suffix = f\"Base{base_number} Log Transformed\"\n",
        "\n",
        "    # Set plot title and axis labels\n",
        "    fig.update_layout(\n",
        "        title=f'iBAQ Profile plot {protein_names} {log_transformed_suffix}',\n",
        "        xaxis_title='Sample',\n",
        "        yaxis_title='iBAQ Value'\n",
        "    )\n",
        "\n",
        "    # Show the plot\n",
        "    fig.show()"
      ],
      "metadata": {
        "id": "9vnzVbY_IVXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you have an excel workbook where each complex has a seprate sheet and each protein in the complex is in a different row (each protein may have different identifiers,) then this cell lets you plot profiles of various proteins from the *workbook*. It also lets you pick alternate legend labels."
      ],
      "metadata": {
        "id": "VHY6UXDATS5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# By user complexes\n",
        "\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "\n",
        "# Load the complexes workbook\n",
        "complexes_path = '/content/FGU13.xlsx'\n",
        "complexes_xls = pd.ExcelFile(complexes_path)\n",
        "\n",
        "# List available sheet names (complexes)\n",
        "print(\"Available complexes:\")\n",
        "for i, sheet_name in enumerate(complexes_xls.sheet_names):\n",
        "    print(f\"{i + 1}: {sheet_name}\")\n",
        "\n",
        "# Prompt the user to select one or more complexes (sheets) by entering numbers\n",
        "complex_choices = input(\"Enter the numbers of the complexes you are interested in (comma-separated, e.g., 1,3,5): \")\n",
        "complex_choices = [int(num) - 1 for num in complex_choices.split(',')]  # Convert input to a list of indices\n",
        "\n",
        "# Initialize lists to collect protein names and corresponding sheet names\n",
        "all_protein_names = []\n",
        "\n",
        "for complex_choice in complex_choices:\n",
        "    complex_sheet_name = complexes_xls.sheet_names[complex_choice]\n",
        "    complex_df = pd.read_excel(complexes_xls, sheet_name=complex_sheet_name)\n",
        "\n",
        "    # Display available columns in the selected complex\n",
        "    print(f\"\\nColumns in {complex_sheet_name}:\")\n",
        "    for i, col_name in enumerate(complex_df.columns):\n",
        "        print(f\"{i + 1}: {col_name}\")\n",
        "\n",
        "    # Prompt the user to select a column from each selected complex\n",
        "    column_choice = int(input(f\"Enter the number of the column you want to use for {complex_sheet_name}: \")) - 1\n",
        "    selected_column_name = complex_df.columns[column_choice]\n",
        "\n",
        "    # Get the names of the proteins from the selected column\n",
        "    protein_names = complex_df[selected_column_name].dropna().tolist()\n",
        "    all_protein_names.extend(protein_names)  # Append protein names for this sheet\n",
        "\n",
        "# Load the abundances file\n",
        "test_pfd_path = '/content/proteinGroups_filtered_2id_selection.txt'\n",
        "test_pfd_df = pd.read_csv(test_pfd_path, sep='\\t')\n",
        "\n",
        "# Ask the user how many identifier columns are present\n",
        "num_identifier_columns = int(input(\"\\nHow many identifier columns do you have (1 or 2)? \"))\n",
        "\n",
        "if num_identifier_columns == 2:\n",
        "    # Display options for the identifier columns in test_pfd.txt\n",
        "    print(\"\\nSelect the identifier column in test_pfd.txt to search for these names:\")\n",
        "    print(f\"1: {test_pfd_df.columns[0]} (first column identifier)\")\n",
        "    print(f\"2: {test_pfd_df.columns[1]} (second column identifier)\")\n",
        "\n",
        "    # Prompt the user to select the identifier column\n",
        "    identifier_choice = int(input(\"Enter 1 or 2: \")) - 1\n",
        "    identifier_column_name = test_pfd_df.columns[identifier_choice]\n",
        "\n",
        "    # Ask user how they want to label the lines in the legend\n",
        "    print(\"\\nHow would you like the lines to be labeled?\")\n",
        "    print(f\"1: Use {test_pfd_df.columns[0]}\")\n",
        "    print(f\"2: Use {test_pfd_df.columns[1]}\")\n",
        "    print(f\"3: Combine both {test_pfd_df.columns[0]} and {test_pfd_df.columns[1]}\")\n",
        "\n",
        "    label_choice = int(input(\"Enter 1, 2, or 3: \"))\n",
        "else:\n",
        "    # Default to using the first column if only one identifier column is selected\n",
        "    identifier_column_name = test_pfd_df.columns[0]\n",
        "    label_choice = 1\n",
        "\n",
        "# Find matching rows in test_pfd.txt based on the selected proteins\n",
        "# Modified to check if IDs may be inside groupings (e.g., separated by semicolons)\n",
        "matching_rows = test_pfd_df[test_pfd_df[identifier_column_name].apply(\n",
        "    lambda cell: isinstance(cell, str) and any(protein in cell.split(';') for protein in all_protein_names)\n",
        ")]\n",
        "\n",
        "if matching_rows.empty:\n",
        "    print(\"No matching proteins found in the selected identifier column.\")\n",
        "else:\n",
        "    # Prepare the data for the profile plot\n",
        "    x_values = test_pfd_df.columns[2:]  # X-axis values from the headers (excluding the first two columns)\n",
        "\n",
        "    # Collect data for each matching row\n",
        "    line_data = []\n",
        "    line_labels = []\n",
        "\n",
        "    for _, row in matching_rows.iterrows():\n",
        "        y_values = row[2:].values  # Y-values for the line\n",
        "        y_values = pd.to_numeric(y_values, errors='coerce')  # Ensure values are numeric\n",
        "        y_values = np.nan_to_num(y_values)  # Replace NaNs with 0\n",
        "\n",
        "        # Determine the row label based on the chosen labeling option\n",
        "        if label_choice == 1:\n",
        "            row_label = row[test_pfd_df.columns[0]]\n",
        "        elif label_choice == 2:\n",
        "            row_label = row[test_pfd_df.columns[1]]\n",
        "        elif label_choice == 3:\n",
        "            row_label = f\"{row[test_pfd_df.columns[0]]} / {row[test_pfd_df.columns[1]]}\"\n",
        "        else:\n",
        "            row_label = row[identifier_column_name]  # Fallback to the chosen identifier column\n",
        "\n",
        "        # Append the data and label to the lists\n",
        "        line_data.append(y_values)\n",
        "        line_labels.append(row_label)\n",
        "\n",
        "    # Determine if the file is log-transformed based on its name\n",
        "    filename = os.path.basename(test_pfd_path)\n",
        "    log_transformed_suffix = \"\"\n",
        "    if \"_Natural\" in filename:\n",
        "        log_transformed_suffix = \"Natural Log Transformed\"\n",
        "    elif \"_Binary\" in filename:\n",
        "        log_transformed_suffix = \"Binary Log Transformed\"\n",
        "    elif \"_Common\" in filename:\n",
        "        log_transformed_suffix = \"Common Log Transformed\"\n",
        "    elif \"_Base\" in filename:\n",
        "        # Extract the base number using a regular expression\n",
        "        base_match = re.search(r\"_Base(\\d+)\", filename)\n",
        "        if base_match:\n",
        "            base_number = base_match.group(1)  # Get the number after \"_Base\"\n",
        "            log_transformed_suffix = f\"Base{base_number} Log Transformed\"\n",
        "\n",
        "    # Create the profile plot\n",
        "    fig = go.Figure()\n",
        "\n",
        "    for i, y_values in enumerate(line_data):\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=x_values,\n",
        "            y=y_values,\n",
        "            mode='lines',\n",
        "            name=line_labels[i]\n",
        "        ))\n",
        "\n",
        "    # Set plot title and axis labels\n",
        "    fig.update_layout(\n",
        "        title=f'Protein iBAQ Profile Plot for Selected Complexes {log_transformed_suffix}',\n",
        "        xaxis_title='Sample',\n",
        "        height=1000,\n",
        "        width=4000,\n",
        "        yaxis_title='iBAQ Value',\n",
        "        yaxis=dict(automargin=True)  # Automatically adjust margins to avoid overlap\n",
        "    )\n",
        "\n",
        "    # Show the plot\n",
        "    fig.show()\n"
      ],
      "metadata": {
        "id": "rSks-TpSffF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Heatmaps**"
      ],
      "metadata": {
        "id": "hhZfhKtBUhyn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell lets you plot heatmaps of various proteins from the filtered sheet. It also lets you pick alternate legend labels."
      ],
      "metadata": {
        "id": "nEn8T4ndTl3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# By ID\n",
        "\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "import os\n",
        "import re  # Import the regular expression module\n",
        "\n",
        "\n",
        "# Function to limit the number of characters per label\n",
        "\n",
        "def truncate_labels(labels, max_length=10):\n",
        "    return [label if len(label) <= max_length else label[:max_length] + '...' for label in labels]\n",
        "\n",
        "# Load the test_pfd.txt file\n",
        "test_pfd_path = '/content/proteinGroups_filtered_2id_selection.txt'\n",
        "test_pfd_df = pd.read_csv(test_pfd_path, sep='\\t')\n",
        "\n",
        "# Ask how many identifier columns are in the file\n",
        "num_identifier_columns = input(\"How many columns do you have as identifiers? (1 or 2): \")\n",
        "\n",
        "# Display options for identifier column (for input)\n",
        "print(\"Select the identifier column you want to use to input protein names:\")\n",
        "if num_identifier_columns == '1':\n",
        "    print(f\"1: {test_pfd_df.columns[0]} (first column identifier)\")\n",
        "    identifier_choice_input = '1'  # Automatically set to the first column\n",
        "elif num_identifier_columns == '2':\n",
        "    print(f\"1: {test_pfd_df.columns[0]} (first column identifier)\")\n",
        "    print(f\"2: {test_pfd_df.columns[1]} (second column identifier)\")\n",
        "    identifier_choice_input = input(\"Enter 1 or 2: \")\n",
        "else:\n",
        "    raise ValueError(\"Invalid number of identifier columns. Please enter 1 or 2.\")\n",
        "\n",
        "# Display options for legend labels\n",
        "print(\"Select the identifier column(s) you want to use for row labels:\")\n",
        "if num_identifier_columns == '1':\n",
        "    print(f\"1: {test_pfd_df.columns[0]} (first column identifier)\")\n",
        "    identifier_choice_legend = '1'  # Automatically set to the first column\n",
        "elif num_identifier_columns == '2':\n",
        "    print(f\"1: {test_pfd_df.columns[0]} (first column identifier)\")\n",
        "    print(f\"2: {test_pfd_df.columns[1]} (second column identifier)\")\n",
        "    print(\"3: Combine both columns as identifiers\")\n",
        "    identifier_choice_legend = input(\"Enter 1, 2, or 3: \")\n",
        "else:\n",
        "    raise ValueError(\"Invalid number of identifier columns. Please enter 1 or 2.\")\n",
        "\n",
        "# Prompt the user for the list of protein names\n",
        "protein_names = input(\"Enter the protein names separated by commas: \").split(',')\n",
        "\n",
        "# Clean up the protein names list and reverse the order\n",
        "protein_names = [protein.strip() for protein in protein_names if protein]  # Remove any empty strings\n",
        "protein_names = protein_names[::-1]  # Reverse the input order of proteins\n",
        "\n",
        "# Choose the appropriate column for input identifiers\n",
        "if identifier_choice_input == '1':\n",
        "    input_column = test_pfd_df.columns[0]\n",
        "elif identifier_choice_input == '2':\n",
        "    input_column = test_pfd_df.columns[1]\n",
        "\n",
        "# Find the matching rows in test_pfd.txt based on the input protein names\n",
        "# Modified to check if IDs may be inside grouping (e.g., separated by semicolons)\n",
        "matching_rows = test_pfd_df[test_pfd_df[input_column].apply(\n",
        "    lambda cell: isinstance(cell, str) and any(protein in cell.split(';') for protein in protein_names)\n",
        ")]\n",
        "\n",
        "if matching_rows.empty:\n",
        "    print(\"No matching proteins found in the selected identifier column.\")\n",
        "else:\n",
        "    # Prepare the data for the heatmap\n",
        "    x_values = test_pfd_df.columns[2:]  # X-axis values from the headers (excluding the first two columns)\n",
        "    # Collect data for each row in the heatmap\n",
        "    heatmap_data = []\n",
        "    row_labels = []\n",
        "\n",
        "    for _, row in matching_rows.iterrows():\n",
        "        y_values = row[2:].values  # Y-values for the heatmap\n",
        "        y_values = pd.to_numeric(y_values, errors='coerce')  # Ensure values are numeric\n",
        "        y_values = np.nan_to_num(y_values)  # Replace NaNs with 0\n",
        "\n",
        "        # Determine the row label based on the user's choice\n",
        "        if identifier_choice_legend == '1':\n",
        "            row_label = row[test_pfd_df.columns[0]]  # First column identifier\n",
        "        elif identifier_choice_legend == '2':\n",
        "            row_label = row[test_pfd_df.columns[1]]  # Second column identifier\n",
        "        elif identifier_choice_legend == '3':\n",
        "            row_label = f\"{row[test_pfd_df.columns[0]]} / {row[test_pfd_df.columns[1]]}\"  # Combined identifiers\n",
        "\n",
        "        # Append the data and label to the lists\n",
        "        heatmap_data.append(y_values)\n",
        "        row_labels.append(row_label)\n",
        "\n",
        "\n",
        "    # Truncate the row labels if they exceed a certain length\n",
        "\n",
        "    max_char_length = 25  # You can adjust the maximum number of characters allowed per label\n",
        "\n",
        "    row_labels = truncate_labels(row_labels, max_length=max_char_length) # Hash this out if you dont want label truncation\n",
        "\n",
        "\n",
        "    # Check if log transformation is to be applied and identify the base\n",
        "    filename = os.path.basename(test_pfd_path)\n",
        "    log_transformed_suffix = \"\"\n",
        "    apply_log_transform = True  # Set this to True or False depending on your preference\n",
        "\n",
        "    if apply_log_transform:\n",
        "        # Determine the log transformation type based on file name\n",
        "        if \"_Natural\" in filename:\n",
        "            log_transformed_suffix = \"Natural Log Transformed\"\n",
        "        elif \"_Binary\" in filename:\n",
        "            log_transformed_suffix = \"Binary Log Transformed\"\n",
        "        elif \"_Common\" in filename:\n",
        "            log_transformed_suffix = \"Common Log Transformed\"\n",
        "        elif \"_Base\" in filename:\n",
        "            # Extract the base number using a regular expression\n",
        "            base_match = re.search(r\"_Base(\\d+)\", filename)\n",
        "            if base_match:\n",
        "                base_number = base_match.group(1)  # Get the number after \"_Base\"\n",
        "                log_transformed_suffix = f\"Base{base_number} Log Transformed\"\n",
        "\n",
        "        # Apply log transformation to heatmap data\n",
        "        #heatmap_data = [np.log1p(row) for row in heatmap_data]  # Apply log1p to each row individually\n",
        "\n",
        "        # Count the number of proteins to be visualized\n",
        "        num_proteins = len(row_labels)\n",
        "\n",
        "        # Define a scaling factor to adjust the plot height and a minimum height\n",
        "        height_scaling_factor = 40  # You can change this number as needed\n",
        "        min_plot_height = 200  # Minimum height for the plot\n",
        "\n",
        "        # Calculate the height of the plot based on the number of proteins\n",
        "        plot_height = max(num_proteins * height_scaling_factor, min_plot_height)\n",
        "\n",
        "\n",
        "    # Create the heatmap\n",
        "    fig = go.Figure(data=go.Heatmap(\n",
        "        z=heatmap_data,\n",
        "        x=x_values,\n",
        "        y=row_labels,\n",
        "        colorscale='Viridis',  # You can change the colorscale if desired\n",
        "        hoverinfo=\"x+y+z\"\n",
        "    ))\n",
        "\n",
        "    # Set plot title and axis labels with automargin enabled\n",
        "    fig.update_layout(\n",
        "        title=f'iBAQ Heatmap {protein_names} {log_transformed_suffix}',\n",
        "        xaxis_title='Sample',\n",
        "        yaxis_title='Proteins',\n",
        "        #width=700,  # You can adjust this value\n",
        "        #height=1000,  # You can adjust this value based on the number of proteins\n",
        "        yaxis=dict(automargin=True)  # Automatically adjust margins to avoid overlap\n",
        "    )\n",
        "\n",
        "    # Show the plot\n",
        "    fig.show()\n"
      ],
      "metadata": {
        "id": "hu_nWf96KWU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you have an excel workbook where each complex has a seprate sheet and each protein in the complex is in a different row (each protein may have different identifiers,) then this cell lets you plot profiles of various proteins from the *workbook*. It also lets you pick alternate legend labels."
      ],
      "metadata": {
        "id": "AkK3IQAHTyB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# By user complexes, single label\n",
        "\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "import os\n",
        "import re  # Import the regular expression module\n",
        "\n",
        "# Function to limit the number of characters in tick labels\n",
        "def limit_label_length(labels, max_length):\n",
        "    return [label if len(label) <= max_length else label[:max_length] + \"...\" for label in labels]\n",
        "\n",
        "# Load the Excel workbook\n",
        "complexes_path = '/content/FGU13.xlsx'\n",
        "complexes_xls = pd.ExcelFile(complexes_path)\n",
        "\n",
        "# List available sheet names (complexes)\n",
        "print(\"Available complexes:\")\n",
        "for i, sheet_name in enumerate(complexes_xls.sheet_names):\n",
        "    print(f\"{i + 1}: {sheet_name}\")\n",
        "\n",
        "# Prompt the user to select one or more complexes (sheets) by entering numbers\n",
        "complex_choices = input(\"Enter the numbers of the complexes you are interested in (comma-separated, e.g., 1,3,5): \")\n",
        "complex_choices = [int(num) - 1 for num in complex_choices.split(',')]  # Convert input to a list of indices\n",
        "\n",
        "# Load the selected sheets and keep track of the order of protein names\n",
        "all_protein_names = []\n",
        "\n",
        "for complex_choice in complex_choices:\n",
        "    complex_sheet_name = complexes_xls.sheet_names[complex_choice]\n",
        "    complex_df = pd.read_excel(complexes_xls, sheet_name=complex_sheet_name)\n",
        "\n",
        "    # Display available columns in the selected complex\n",
        "    print(f\"\\nColumns in {complex_sheet_name}:\")\n",
        "    for i, col_name in enumerate(complex_df.columns):\n",
        "        print(f\"{i + 1}: {col_name}\")\n",
        "\n",
        "    # Prompt the user to select a column from each selected complex\n",
        "    column_choice = int(input(f\"Enter the number of the column you want to use for {complex_sheet_name}: \")) - 1\n",
        "    selected_column_name = complex_df.columns[column_choice]\n",
        "\n",
        "    # Get the names of the proteins from the selected column and maintain order\n",
        "    protein_names = complex_df[selected_column_name].dropna().tolist()\n",
        "    all_protein_names.append(protein_names)  # Append the list of proteins for this sheet\n",
        "\n",
        "# Flatten the list of protein names while maintaining order across sheets\n",
        "ordered_protein_names = [protein for sublist in all_protein_names for protein in sublist]\n",
        "\n",
        "# Invert the order of the protein names\n",
        "ordered_protein_names.reverse()\n",
        "\n",
        "# Load the test_pfd.txt file\n",
        "test_pfd_path = '/content/newtest_pfd2_Binary.txt'\n",
        "test_pfd_df = pd.read_csv(test_pfd_path, sep='\\t')\n",
        "\n",
        "# Ask how many identifier columns are in the file\n",
        "num_identifier_columns = input(\"How many columns do you have as identifiers? (1 or 2): \")\n",
        "\n",
        "# Display options for identifier column (for input)\n",
        "print(\"\\nSelect the identifier column in test_pfd.txt to search for these names:\")\n",
        "if num_identifier_columns == '1':\n",
        "    print(f\"1: {test_pfd_df.columns[0]} (first column identifier)\")\n",
        "    identifier_choice = '1'  # Automatically set to the first column\n",
        "elif num_identifier_columns == '2':\n",
        "    print(f\"1: {test_pfd_df.columns[0]} (first column identifier)\")\n",
        "    print(f\"2: {test_pfd_df.columns[1]} (second column identifier)\")\n",
        "    identifier_choice = input(\"Enter 1 or 2: \")\n",
        "else:\n",
        "    raise ValueError(\"Invalid number of identifier columns. Please enter 1 or 2.\")\n",
        "\n",
        "# Choose the appropriate column for input identifiers\n",
        "identifier_column_name = test_pfd_df.columns[int(identifier_choice) - 1]\n",
        "\n",
        "# Ask the user how they would like the lines to be labeled (three options)\n",
        "print(\"\\nHow would you like the lines to be labeled?\")\n",
        "print(f\"1: {test_pfd_df.columns[0]} (first column identifier)\")\n",
        "if num_identifier_columns == '2':\n",
        "    print(f\"2: {test_pfd_df.columns[1]} (second column identifier)\")\n",
        "    print(\"3: Combine both columns as identifiers\")\n",
        "    label_choice = input(\"Enter 1, 2, or 3: \")\n",
        "else:\n",
        "    label_choice = '1'  # Automatically set to first column if only one column exists\n",
        "\n",
        "# Find matching rows in test_pfd.txt based on the ordered protein names\n",
        "matching_rows = []\n",
        "\n",
        "for protein in ordered_protein_names:\n",
        "    matches = test_pfd_df[test_pfd_df[identifier_column_name].apply(\n",
        "        lambda cell: isinstance(cell, str) and protein in cell.split(';'))\n",
        "    ]\n",
        "    if not matches.empty:\n",
        "        matching_rows.append(matches.iloc[0])  # Get the first match for each protein\n",
        "\n",
        "if not matching_rows:\n",
        "    print(\"No matching proteins found in the selected identifier column.\")\n",
        "else:\n",
        "    # Prepare the data for the heatmap\n",
        "    x_values = test_pfd_df.columns[2:]  # X-axis values from the headers (excluding the first two columns)\n",
        "\n",
        "    # Collect data for the heatmap\n",
        "    heatmap_data = []\n",
        "    y_labels = []\n",
        "\n",
        "    for row in matching_rows:\n",
        "        y_values = row[2:].values  # Y-values for the heatmap\n",
        "        y_values = pd.to_numeric(y_values, errors='coerce')  # Ensure values are numeric\n",
        "        y_values = np.nan_to_num(y_values)  # Replace NaNs with 0\n",
        "\n",
        "        # Determine the row label based on the user's choice\n",
        "        if label_choice == '1':\n",
        "            row_label = row[test_pfd_df.columns[0]]  # First column identifier\n",
        "        elif label_choice == '2':\n",
        "            row_label = row[test_pfd_df.columns[1]]  # Second column identifier\n",
        "        elif label_choice == '3':\n",
        "            row_label = f\"{row[test_pfd_df.columns[0]]} / {row[test_pfd_df.columns[1]]}\"  # Combined identifiers\n",
        "\n",
        "        # Append the data and label to the lists\n",
        "        heatmap_data.append(y_values)\n",
        "        y_labels.append(row_label)\n",
        "\n",
        "    # Limit the label length (e.g., to 20 characters)\n",
        "    max_label_length = 20  # You can change this value\n",
        "    y_labels = limit_label_length(y_labels, max_label_length)\n",
        "\n",
        "    # Check if log transformation is to be applied and identify the base\n",
        "    filename = os.path.basename(test_pfd_path)\n",
        "    log_transformed_suffix = \"\"\n",
        "    apply_log_transform = True  # Set this to True or False depending on your preference\n",
        "\n",
        "    if apply_log_transform:\n",
        "        # Determine the log transformation type based on file name\n",
        "        if \"_Natural\" in filename:\n",
        "            log_transformed_suffix = \"Natural Log Transformed\"\n",
        "        elif \"_Binary\" in filename:\n",
        "            log_transformed_suffix = \"Binary Log Transformed\"\n",
        "        elif \"_Common\" in filename:\n",
        "            log_transformed_suffix = \"Common Log Transformed\"\n",
        "        elif \"_Base\" in filename:\n",
        "            # Extract the base number using a regular expression\n",
        "            base_match = re.search(r\"_Base(\\d+)\", filename)\n",
        "            if base_match:\n",
        "                base_number = base_match.group(1)  # Get the number after \"_Base\"\n",
        "                log_transformed_suffix = f\"Base{base_number} Log Transformed\"\n",
        "\n",
        "        # Apply log transformation to heatmap data if required\n",
        "        # heatmap_data = [np.log1p(row) for row in heatmap_data]  # Example: log transformation\n",
        "\n",
        "        # Define a scaling factor to adjust the plot height and a minimum height\n",
        "        height_scaling_factor = 40  # You can change this number as needed\n",
        "        min_plot_height = 200  # Minimum height for the plot\n",
        "\n",
        "        # Calculate the height of the plot based on the number of proteins\n",
        "        plot_height = max(len(y_labels) * height_scaling_factor, min_plot_height)\n",
        "\n",
        "    # Create the heatmap\n",
        "    fig = go.Figure(data=go.Heatmap(\n",
        "        z=heatmap_data,\n",
        "        x=x_values,\n",
        "        y=y_labels,\n",
        "        colorscale='Viridis'\n",
        "    ))\n",
        "\n",
        "    # Set plot title and axis labels\n",
        "    fig.update_layout(\n",
        "        title=f'Protein iBAQ Heatmap for Selected Complexes - {log_transformed_suffix}',\n",
        "        xaxis_title='Sample',\n",
        "        yaxis_title='Proteins',\n",
        "        width=2800,  # You can adjust this value\n",
        "        height=1200,  # Adjust the plot height dynamically\n",
        "        yaxis=dict(automargin=True)  # Automatically adjust margins to avoid overlap\n",
        "    )\n",
        "\n",
        "    # Show the plot\n",
        "    fig.show()\n"
      ],
      "metadata": {
        "id": "ouVsTPiihET7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell is similar to the previous one except it adds extended labels with complex names"
      ],
      "metadata": {
        "id": "Jf-nC_wvT38u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "import os\n",
        "import re  # Import the regular expression module\n",
        "\n",
        "# Function to limit the number of characters in tick labels and append sheet name\n",
        "def limit_label_length(labels, max_length, sheet_names):\n",
        "    return [\n",
        "        (label if len(label) <= max_length else label[:max_length] + \"...\") + f\" ({sheet})\"\n",
        "        for label, sheet in zip(labels, sheet_names)\n",
        "    ]\n",
        "\n",
        "# Load the Excel workbook\n",
        "complexes_path = '/content/FGU13.xlsx'\n",
        "complexes_xls = pd.ExcelFile(complexes_path)\n",
        "\n",
        "# List available sheet names (complexes)\n",
        "print(\"Available complexes:\")\n",
        "for i, sheet_name in enumerate(complexes_xls.sheet_names):\n",
        "    print(f\"{i + 1}: {sheet_name}\")\n",
        "\n",
        "# Prompt the user to select one or more complexes (sheets) by entering numbers\n",
        "complex_choices = input(\"Enter the numbers of the complexes you are interested in (comma-separated, e.g., 1,3,5): \")\n",
        "complex_choices = [int(num) - 1 for num in complex_choices.split(',')]  # Convert input to a list of indices\n",
        "\n",
        "# Load the selected sheets and keep track of the order of protein names\n",
        "all_protein_names = []\n",
        "all_sheet_names = []  # To store the corresponding sheet name for each protein\n",
        "\n",
        "for complex_choice in complex_choices:\n",
        "    complex_sheet_name = complexes_xls.sheet_names[complex_choice]\n",
        "    complex_df = pd.read_excel(complexes_xls, sheet_name=complex_sheet_name)\n",
        "\n",
        "    # Display available columns in the selected complex\n",
        "    print(f\"\\nColumns in {complex_sheet_name}:\")\n",
        "    for i, col_name in enumerate(complex_df.columns):\n",
        "        print(f\"{i + 1}: {col_name}\")\n",
        "\n",
        "    # Prompt the user to select a column from each selected complex\n",
        "    column_choice = int(input(f\"Enter the number of the column you want to use for {complex_sheet_name}: \")) - 1\n",
        "    selected_column_name = complex_df.columns[column_choice]\n",
        "\n",
        "    # Get the names of the proteins from the selected column and maintain order\n",
        "    protein_names = complex_df[selected_column_name].dropna().tolist()\n",
        "    all_protein_names.append(protein_names)  # Append the list of proteins for this sheet\n",
        "    all_sheet_names.extend([complex_sheet_name] * len(protein_names))  # Append sheet name for each protein\n",
        "\n",
        "# Flatten the list of protein names while maintaining order across sheets\n",
        "ordered_protein_names = [protein for sublist in all_protein_names for protein in sublist]\n",
        "\n",
        "# Invert the order of the protein names\n",
        "ordered_protein_names.reverse()\n",
        "all_sheet_names.reverse()  # Reverse the corresponding sheet names\n",
        "\n",
        "# Load the test_pfd.txt file\n",
        "test_pfd_path = '/content/newtest_pfd2_Binary.txt'\n",
        "test_pfd_df = pd.read_csv(test_pfd_path, sep='\\t')\n",
        "\n",
        "# Ask how many identifier columns are in the file\n",
        "num_identifier_columns = input(\"How many columns do you have as identifiers? (1 or 2): \")\n",
        "\n",
        "# Display options for identifier column (for input)\n",
        "print(\"\\nSelect the identifier column in test_pfd.txt to search for these names:\")\n",
        "if num_identifier_columns == '1':\n",
        "    print(f\"1: {test_pfd_df.columns[0]} (first column identifier)\")\n",
        "    identifier_choice = '1'  # Automatically set to the first column\n",
        "elif num_identifier_columns == '2':\n",
        "    print(f\"1: {test_pfd_df.columns[0]} (first column identifier)\")\n",
        "    print(f\"2: {test_pfd_df.columns[1]} (second column identifier)\")\n",
        "    identifier_choice = input(\"Enter 1 or 2: \")\n",
        "else:\n",
        "    raise ValueError(\"Invalid number of identifier columns. Please enter 1 or 2.\")\n",
        "\n",
        "# Choose the appropriate column for input identifiers\n",
        "identifier_column_name = test_pfd_df.columns[int(identifier_choice) - 1]\n",
        "\n",
        "# Ask the user how they would like the lines to be labeled (three options)\n",
        "print(\"\\nHow would you like the lines to be labeled?\")\n",
        "print(f\"1: {test_pfd_df.columns[0]} (first column identifier)\")\n",
        "if num_identifier_columns == '2':\n",
        "    print(f\"2: {test_pfd_df.columns[1]} (second column identifier)\")\n",
        "    print(\"3: Combine both columns as identifiers\")\n",
        "    label_choice = input(\"Enter 1, 2, or 3: \")\n",
        "else:\n",
        "    label_choice = '1'  # Automatically set to first column if only one column exists\n",
        "\n",
        "# Find matching rows in test_pfd.txt based on the ordered protein names\n",
        "matching_rows = []\n",
        "\n",
        "for protein in ordered_protein_names:\n",
        "    matches = test_pfd_df[test_pfd_df[identifier_column_name].apply(\n",
        "        lambda cell: isinstance(cell, str) and protein in cell.split(';'))\n",
        "    ]\n",
        "    if not matches.empty:\n",
        "        matching_rows.append(matches.iloc[0])  # Get the first match for each protein\n",
        "\n",
        "if not matching_rows:\n",
        "    print(\"No matching proteins found in the selected identifier column.\")\n",
        "else:\n",
        "    # Prepare the data for the heatmap\n",
        "    x_values = test_pfd_df.columns[2:]  # X-axis values from the headers (excluding the first two columns)\n",
        "\n",
        "    # Collect data for the heatmap\n",
        "    heatmap_data = []\n",
        "    y_labels = []\n",
        "\n",
        "    for row in matching_rows:\n",
        "        y_values = row[2:].values  # Y-values for the heatmap\n",
        "        y_values = pd.to_numeric(y_values, errors='coerce')  # Ensure values are numeric\n",
        "        y_values = np.nan_to_num(y_values)  # Replace NaNs with 0\n",
        "\n",
        "        # Determine the row label based on the user's choice\n",
        "        if label_choice == '1':\n",
        "            row_label = row[test_pfd_df.columns[0]]  # First column identifier\n",
        "        elif label_choice == '2':\n",
        "            row_label = row[test_pfd_df.columns[1]]  # Second column identifier\n",
        "        elif label_choice == '3':\n",
        "            row_label = f\"{row[test_pfd_df.columns[0]]} / {row[test_pfd_df.columns[1]]}\"  # Combined identifiers\n",
        "\n",
        "        # Append the data and label to the lists\n",
        "        heatmap_data.append(y_values)\n",
        "        y_labels.append(row_label)\n",
        "\n",
        "    # Limit the label length (e.g., to 20 characters) and append the sheet name\n",
        "    max_label_length = 20  # You can change this value\n",
        "    y_labels = limit_label_length(y_labels, max_label_length, all_sheet_names)\n",
        "\n",
        "    # Check if log transformation is to be applied and identify the base\n",
        "    filename = os.path.basename(test_pfd_path)\n",
        "    log_transformed_suffix = \"\"\n",
        "    apply_log_transform = True  # Set this to True or False depending on your preference\n",
        "\n",
        "    if apply_log_transform:\n",
        "        # Determine the log transformation type based on file name\n",
        "        if \"_Natural\" in filename:\n",
        "            log_transformed_suffix = \"Natural Log Transformed\"\n",
        "        elif \"_Binary\" in filename:\n",
        "            log_transformed_suffix = \"Binary Log Transformed\"\n",
        "        elif \"_Common\" in filename:\n",
        "            log_transformed_suffix = \"Common Log Transformed\"\n",
        "        elif \"_Base\" in filename:\n",
        "            # Extract the base number using a regular expression\n",
        "            base_match = re.search(r\"_Base(\\d+)\", filename)\n",
        "            if base_match:\n",
        "                base_number = base_match.group(1)  # Get the number after \"_Base\"\n",
        "                log_transformed_suffix = f\"Base{base_number} Log Transformed\"\n",
        "\n",
        "        # Define a scaling factor to adjust the plot height and a minimum height\n",
        "        height_scaling_factor = 40  # You can change this number as needed\n",
        "        min_plot_height = 200  # Minimum height for the plot\n",
        "\n",
        "        # Calculate the height of the plot based on the number of proteins\n",
        "        plot_height = max(len(y_labels) * height_scaling_factor, min_plot_height)\n",
        "\n",
        "    # Create the heatmap\n",
        "    fig = go.Figure(data=go.Heatmap(\n",
        "        z=heatmap_data,\n",
        "        x=x_values,\n",
        "        y=y_labels,\n",
        "        colorscale='Viridis'\n",
        "    ))\n",
        "\n",
        "    # Set plot title and axis labels\n",
        "    fig.update_layout(\n",
        "        title=f'Protein iBAQ Heatmap for Selected Complexes - {log_transformed_suffix}',\n",
        "        xaxis_title='Sample',\n",
        "        yaxis_title='Proteins',\n",
        "        width=2800,  # You can adjust this value\n",
        "        height=1200,  # Adjust the plot height dynamically\n",
        "        yaxis=dict(automargin=True)  # Automatically adjust margins to avoid overlap\n",
        "    )\n",
        "\n",
        "    # Show the plot\n",
        "    fig.show()\n"
      ],
      "metadata": {
        "id": "8tWm8Z2LFEOZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}